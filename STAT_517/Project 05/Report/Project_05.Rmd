---
title: "Snow"
author: "Kaisa Roggeveen, Scott Graham"
date: "April 10th, 2018"
header-includes:
  - \newcommand{\Prob}{\operatorname{P}}
  - \newcommand{\E}{\operatorname{E}}
  - \newcommand{\Var}{\operatorname{Var}}
  - \newcommand{\Cov}{\operatorname{Cov}}
  - \newcommand{\se}{\operatorname{se}}
  - \newcommand{\re}{\operatorname{re}}
  - \newcommand{\ybar}{{\overline{Y}}}
  - \newcommand{\phat}{{\hat{p}}}
  - \newcommand{\that}{{\hat{T}}}
  - \newcommand{\med}{{\tilde{Y}}}
  - \newcommand{\logit}{{\operatorname{Logit}}}
output: 
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(pander, warn.conflicts = FALSE, quietly = TRUE)
library(knitr, warn.conflicts = FALSE, quietly = TRUE)
library(tidyverse, warn.conflicts = FALSE, quietly = TRUE)
library(ggfortify, warn.conflicts = FALSE, quietly = TRUE)

theme_minimal2 <- theme_minimal() %>%  theme_set()
theme_minimal2 <-
  theme_update(
    panel.border = element_rect(
      linetype = "solid"
      ,colour = "grey92"
      ,fill = NA
    )
    ,strip.background = element_rect(
      linetype = "solid"
      ,colour = "grey92"
      ,fill = NA
    )
  )

# Data Import ----------
snow_wide <- 
  "../Data/snow_data.csv" %>% 
  read_csv()

snow_long <- 
  snow_wide %>% 
  gather(
    key = Gauge
    ,value = Gain
    ,-Density
  ) %>% 
  mutate(Gauge = as.factor(Gauge))

alpha <- 0.05
```

# Introduction
The intent of this paper is to determine the procedure for calibrating snow gauges. Snow gauges are used to measure the depth and density of a snow pack and are used to help monitor water supply in Northern California. Recently, the state of California has been in a drought [1], and having accurate measurements of their water supply is very important. The information from the snow gauges is critical for helping the state prepare for the dry season and therefore it is critical that the snow gauges are taking accurate measurements. 

The snow gauges in the Sierra Nevada mountains are fixed at one location and able to measure the density of the snow pack without making changes to the snow pack. The snow gauge consists of two vertical poles that are about 70cm apart, where one pole has a gamma ray emitter and the other pole has a detector. Snow with a higher density will be detected less, since the energy waves are scatter by the snow particles and snow with a lower density will let more gamma rays pass through and be detected. 

In order to calibrate the snow gauge, polyethylene blocks are used to mimic the snow at different densities. The same model applies to the polyethylene blocks, blocks with higher density will let less gamma rays reach the detector since the probability of the gamma ray reaching the block decreases and blocks with lower density will let more gamma rays through with a greater probability of reaching the block. 

The probability of the gamma ray being detected follows this model where:
$$P^m$$ 
where $p$ is the probability the gamma ray is not absorbed nor deflected and $m$ is the number of molecules between the gamma ray emitter and the detector. Another expression of the model is: 
$$e^{m\ln(p)} = e^{bx}$$
where $x$ is the density and $b$ is a constant.

## Data
Data sets was provided by the USDA Forest Service's and consists of ten measurements from nine different density of polyethylene block's gain, which is an amplified count of the detected photons, the densities were measured in g/cm^$3$. The gain for the polyethylene blocks was measured for blocks with densities between 0.001 g/cm^$3$ and 0.686 g/cm^$3$. The density of a snow pack usually falls between 0.1 g/cm$^3$ and 0.6 g/cm^$3$

```{r Wide Data}
snow_wide %>% 
  kable(caption = "Gauge Data")
```

To begin the data analysis, the gain versus the density were plotted and the plot is shown in Figure 01. In Figure 01, it can be seen that measurements of gain remain relatively consistent for the 10 measurements taken. Also, in Figure 01, there is a very obvious trend within the measurements, that is as the gain decreases, the density of the polyethylene blocks increase. This is a good indication as to where to start when calibrating a snow gauge.

Figure 02, shows a negative linear relationship between the log of gain versus the density, as the density increases the gain decreases. In this case a logistic model is appropriate because as density increases, the space between the molecules decreases exponentially and therefore as density increases, it is much more likely that a gamma ray will be deflected or absorbed.  

```{r Measured Gain by Gauge}
snow_long %>% 
  ggplot(
    aes(
      x = Gauge
      ,y = log(Gain)
      ,colour = Density
    )
  ) +
  geom_point() +
  facet_grid(
    ~ Gauge
    ,scales = "free_x"
  ) +
  scale_colour_distiller(
    type = "seq"
    ,palette = "OrRd"
    ,direction = 1
  ) +
  labs(
    title = "Figure 01: Measured Gain by Gauge"
    ,colour = expression(paste("Density (g/cm"^3,")"))
  ) +
  theme(
    axis.text.x = element_blank()
    ,axis.title.x = element_blank()
    ,legend.position = "bottom"
  )
```

A subset of the data was collected and used to train the snow gauge. The training set consisted of the first three measurements. The second subset of data consisted of the fourth to tenth measurements and was used to validate the data. In this case a training set is useful to validate our model because it will be testing the fit of our model using cross-validation and the data that has already been collected. Since we do not know the exact method of calibrating a snow gauge using the existing data and testing the model is important for accuracy.

```{r Training Data}
snow_long_train <- 
  snow_long %>%
  filter(Gauge %in% c("G 01", "G 02", "G 03"))

snow_long_valid <-
  snow_long %>%
  filter(!(Gauge %in% c("G 01", "G 02", "G 03")))

snow_long_train %>% 
  ggplot(
    aes(
      x = Density
      ,y = log(Gain)
    )
  ) +
  geom_smooth(method = "lm") +
  geom_point() +
  labs(
    title = "Figure 02: Log Gain vs. Density with Training Data"
    ,x = expression(paste("Density (g/cm"^3,")"))
  )
```

talk about how a log model is appropriate


## Training vs. Validation Data

Talk about how we split the data into training data (Gauges 1-3), and validation data (gauges 4-10). 

# Calibration
## Classic Calibration Method
For the classic calibration method, we regress our measurement ($G:=$ Gain) as a function of the known variable ($D:=$ Density).
```{r LM}
snow_lm <-
  snow_long_train %>% 
  lm(
      log(Gain) ~ Density
    ,data = .
  )

snow_lm %>% 
  summary() %>% 
  pander()
```

From this we take our linear regression model, and invert it, solving for the known predictor variable $D$. This gives us:

$$
  \hat{D_{i}} = 
  -\frac{\ln(G_{i}) - 6.0032 - \epsilon_{i}}{4.6301} =
  1.2965(1+\epsilon_{i}) - 0.2160\ln(G_{i}),
  \epsilon_{i} \stackrel{iid}{\sim} \mathcal{N}(0,\sigma^{2})
$$

From this, we can come up with both the point estimates for $D$, and a prediction interval, using:
$$
  \se\left( \hat{D_{i}} \right) =
  \frac{\sqrt{MSE}}{\hat{\beta_{1}}}\sqrt{1 + \frac{1}{n} + \frac{\left( D_{i}-\bar{D} \right)^{2}}{S_{DD}}},
  MSE = 0.0028,
  \bar{D} = 0.3311\dots,
  S_{DD} = 0.2293
$$

As well as assuming an underlying Student's t-distribution, with $df=n-p=n-2=27-2=25$.

```{r Classic Calibration Est}
classic_calibration <- function(x, object){
  (log(x) - object$coefficients[["(Intercept)"]]) / object$coefficients[["Density"]]
}

snow_summ_valid_cc <-
  snow_long_valid %>% 
  group_by(Density) %>% 
  summarize(`Mean Gain` = mean(Gain)) %>% 
  mutate(
    `Est Density` = classic_calibration(x = `Mean Gain`, object = snow_lm)
    ,`Prediction Std. Error` = 
      sqrt(
        (summary(snow_lm)$sigma/snow_lm$coefficients[[2]])^2 *
        ( 1 + 
            1/nrow(snow_long_train) + 
            (`Est Density` - mean(snow_long_train$Density))^2/sd(snow_long_train$Density) )
      )
    ,`Prediction LB` = `Est Density` - qt(1-alpha/2, snow_lm$df.residual, lower.tail = TRUE) * `Prediction Std. Error`
    ,`Prediction UB` = `Est Density` + qt(1-alpha/2, snow_lm$df.residual, lower.tail = TRUE) * `Prediction Std. Error`
  )
snow_summ_valid_cc %>% 
  kable()
```

From this, we can plot the results, with the Estimated Density on the y-axis, and the Mean Gain for a given Density on the x-axis. The grey band represents the 95\% Prediction Interval for $D$.

```{r CC Dens vs Gain}
snow_summ_valid_cc %>% 
  ggplot(
    aes(
      x = `Mean Gain`
      ,y = `Est Density`
    )
  ) +
  geom_ribbon(
    aes(
      ymin = `Prediction LB`
      ,ymax = `Prediction UB`
    )
    ,fill = "grey60"
    ,alpha = 0.4
  ) +
  stat_function(
    fun = classic_calibration
    ,args = list(object = snow_lm)
  ) +
  geom_point() +
  labs(
    title = "Figure 03: Estimated Density vs. Gain"
    ,subtitle = "With Prediction Interval and Curve"
    ,y = expression(paste("Estimated Density (g/cm"^3,")"))
  )
```

Parker et al. (2010), provides a method for finding a finding the bias in the estimation of $\hat{D_{i}}$:
$$
  \operatorname{bias}\left( \hat{D_{i}} \right) =
  \frac{(D_{i} - \bar{D})MSE}{\hat{\beta_{1}}^{2}S_{DD}}
$$

```{r CC Unbias}
snow_summ_unbias_cc <- 
  snow_summ_valid_cc %>% 
  mutate(
    Bias = 
      (Density - mean(snow_long_train$Density)) * summary(snow_lm)$sigma^2 /
      (snow_lm$coefficients[[2]]^2 * sd(snow_long_train$Density))
    ,`Unbiased Est Density` = `Est Density` - Bias
  ) %>% 
  select(Density, `Est Density`, Bias, `Unbiased Est Density`)
snow_summ_unbias_cc %>% 
  kable(caption = "Unbiasing the Estimated Density for Classic Calibration")

snow_summ_unbias_cc %>% 
  ggplot(
    aes(
      x = Density
      ,y = Bias
    )
  ) +
  geom_line() +
  labs(
    title = "Figure 04: Rate of Change of Bias"
    ,x = expression(paste("Density (g/cm"^3,")"))
    ,y = expression(paste("Estimated Bias (g/cm"^3,")"))
  )
```


## Inverse Regression
The other methodology looked at was using a inverse regression technique, by using $D$ as the dependent variable, and $G$ as the independent variable. This should give us a slightly different result than the coefficients calculated under the classical calibration method, as regression equations don't invert exactly unless the correlation between the two variables is $\pm 1$. Because our correlation (`r cor(snow_long_train$Density, snow_long_train$Gain)`) is close to $-1$, the coefficients will be very close. For this we use the model:

$$
  \hat{D_{i}} =
  \hat{\gamma_{0}} + \hat{\gamma_{1}}\left( \ln(G_{i}) - \overline{\ln(G_{i})} \right) + \epsilon_{i} =
  0.3311 - 02155\left( \ln(G_{i}) - 4.4701 \right) + \epsilon_{i},
  \epsilon_{i} \stackrel{iid}{\sim} \mathcal{N}(0,\sigma^{2})
$$
$$
  \overline{\ln(G)} = \sum_{i=1}^{n}\frac{\ln{G_{i}}}{n},
  \hat{\gamma_{0}} = \bar{D}
$$

```{r Inv LM}
snow_inv_lm <-
  snow_long_train %>% 
  mutate(`Centred Gain` = exp(log(Gain) - mean(log(Gain)))) %>% 
  lm(
    Density ~ log(`Centred Gain`)
    ,data = .
  )
snow_inv_lm %>% 
  summary() %>% 
  pander()
```

As we can see from the regression output, $\hat{\gamma_{0}} = \bar{D}$, which is what we want. We then estimated $\hat{D_{i}}$, and the prediction interval estimate:

$$
  \se\left( \hat{D_{i}} \right) =
  \sqrt{MSE}\sqrt{1 + \frac{1}{n} + \frac{\left( \ln(G_{i})-\overline{\ln(G)} \right)^{2}}{S_{GG}}}
$$

```{r Inverse Reg Est}
inverse_regression <- function(x, object){
  predict(object = object, newdata = tibble(`Centred Gain` = exp(log(x) - mean(log(snow_long_train$Gain)))))
}

snow_summ_valid_ir <-
  snow_long_valid %>% 
  group_by(Density) %>% 
  summarize(
    `Mean Gain` = mean(Gain)
  ) %>% 
  mutate(
    `Mean Centred Gain` = exp(log(`Mean Gain`) - mean(log(snow_long_train$Gain)))
  ) %>% 
  mutate(
    `Est Density` = inverse_regression(x = `Mean Gain`, object = snow_inv_lm)
    ,`Prediction Std. Error` =
      sqrt(
        (summary(snow_inv_lm)$sigma)^2 *
          ( 1 +
              1/nrow(snow_long_train) +
              (log(`Mean Gain`) - mean(log(snow_long_train$Gain)))^2/sd(log(snow_long_train$Gain)) )
      )
    ,`Prediction LB` = `Est Density` - qt(1-alpha/2, snow_inv_lm$df.residual, lower.tail = TRUE) * `Prediction Std. Error`
    ,`Prediction UB` = `Est Density` + qt(1-alpha/2, snow_inv_lm$df.residual, lower.tail = TRUE) * `Prediction Std. Error`
  )
snow_summ_valid_ir %>% 
  kable()
```

As well as recreating the plot used in the classical calibration method. Note that the plot looks very similar, with a marginally large standard error term.

```{r IR Dens vs Gain}
snow_summ_valid_ir %>% 
  ggplot(
    aes(
      x = `Mean Gain`
      ,y = `Est Density`
    )
  ) +
  geom_ribbon(
    aes(
      ymin = `Prediction LB`
      ,ymax = `Prediction UB`
    )
    ,fill = "grey60"
    ,alpha = 0.4
  ) +
  stat_function(
    fun = inverse_regression
    ,args = list(object = snow_inv_lm)
  ) +
  geom_point() +
  labs(
    title = "Figure 05: Estimated Density vs. Gain"
    ,subtitle = "With Prediction Interval and Curve"
    ,y = expression(paste("Estimated Density (g/cm"^3,")"))
  )
```

Parker et al. (2010), provides a means of unbiasing $\hat{D_{i}}$ for inverse regression too:

$$
  \operatorname{bias}\left( \hat{D_{i}} \right) =
  \frac{\bar{D} - D_{i}}{1 + \frac{\hat{\beta_{1}}^{2}S_{DD}}{(n-1)MSE}}
$$

This is then plotted against $D$, to see the rate of change.

```{r IR Unbias}
snow_summ_unbias_ir <- 
  snow_summ_valid_ir %>% 
  mutate(
    Bias = 
      (mean(snow_long_train$Density) - Density) /
      (1 + 
         (snow_inv_lm$coefficients[[2]]^2*sd(snow_long_train$Density))/
         ((nrow(snow_long_train) - 1)*summary(snow_inv_lm)$sigma^2)
      )
    ,`Unbiased Est Density` = `Est Density` - Bias
  ) %>% 
  select(Density, `Est Density`, Bias, `Unbiased Est Density`)
snow_summ_unbias_ir %>% 
  kable(caption = "Unbiasing the Estimated Density for Inverse Regression")

snow_summ_unbias_ir %>% 
  ggplot(
    aes(
      x = Density
      ,y = Bias
    )
  ) +
  geom_line() +
  labs(
    title = "Figure 06: Rate of Change of Bias"
    ,x = expression(paste("Density (g/cm"^3,")"))
    ,y = expression(paste("Estimated Bias (g/cm"^3,")"))
  )
```


## Comparison
```{r Comparison}
snow_summ_unbias_cc %>% 
  select(
    Density
    ,`CC Est Density` = `Est Density`
    ,`CC Bias` = Bias
  ) %>% 
  left_join(
    snow_summ_unbias_ir %>% 
      select(
        Density
        ,`IR Est Density` = `Est Density`
        ,`IR Bias` = Bias
      )
    ,by = "Density"
  ) %>% 
  kable(caption = "Comparison of Bias")

snow_summ_valid_cc %>% 
  select(
    Density
    ,`Mean Gain`
    ,`CC Est Density` = `Est Density`
    ,`CC Prediction Std. Error` = `Prediction Std. Error`
  ) %>% 
  left_join(
    snow_summ_valid_ir %>% 
      select(  
        Density
        ,`Mean Gain`
        ,`IR Est Density` = `Est Density`
        ,`IR Prediction Std. Error` = `Prediction Std. Error`
      )
    ,by = c("Density" = "Density", "Mean Gain" = "Mean Gain")
  ) %>% 
  kable(caption = "Comparison of Standard Error")
```

To compare the two methods, we looked at the size of their Bias, and the size of the Standard Errors. From the two tables above, one can see that the Classic Calibration method outperformed the Inverse Regression by having both a smaller estimated bias, and a smaller estimated standard error based on the same training and validation samples.

## Measurement Error
If we were to assume that the given densities for the polyethylene blocks contained small amounts of measurement error, this change the size of our interval estimates.

Let:
$$
  \hat{D_{i}} =
  D_{i} + \epsilon_{D,i},
  \epsilon_{D,i} \sim \mathcal{N}(0, \sigma^{2}) \implies
$$
$$
  \ln(G_{i}) = 
  \hat{\beta_{0}} + \hat{\beta_{1}}\hat{D_{i}} + \epsilon_{G,i} =
  \hat{\beta_{0}} + \hat{\beta_{1}}(D_{i} + \epsilon_{D,i}) + \epsilon_{G,i} =
$$
$$
  \hat{\beta_{0}} + \hat{\beta_{1}}D_{i} + (\hat{\beta_{1}}\epsilon_{D,i} + \epsilon_{G,i}) =
  \hat{\beta_{0}} + \hat{\beta_{1}}D_{i} + \epsilon^{\star}_{G,i}
$$
Where
$$
  \epsilon^{\star}_{G,i} \sim
  \mathcal{N}\left( 0, \hat{\beta_{1}}^{2}\sigma_{D}^{2}+\sigma_{G}^{2}+2\hat{\beta_{1}}\Cov(D,G) \right)
$$

Now hopefully the covariance term is equal to 0, otherwise additional issues would arise in the calibration. While this won't affect the coefficient estimation done in the regressions, it would affect the size of the interval estimates, by increasing them to reflect the greater uncertainty in the quality of measurements.

# Instructions for Calibration
Materials Required: Ten different polyethylene blocks with the following densities in g/cm^$3$; 0.001, 0.080, 0.148, 0.223, 0.318, 0.412, 0.508, 0.604 and 0.686.

1. Place a polyethylene block between the snow gauge and measure take ten measurements of the gain. 

2. Calculate the mean gain for the polyethylene block.

3. Using the data set provided, determine if the mean gain falls within the lower and upper bounds for the known density. 
  
  + If the gain does not fall within the bounds for the known density, then adjust the gamma ray emission and repeat until the gain falls within the prediction bound.
  
  + If the gain falls within the prediction bound, mark that the gain was accurately read. Repeat the steps with the next block of known densities until all blocks are reading accurately.



# Conclusion
There were two methods, the Classical Calibration method and the Inverse Regression method used for measuring gain. When comparing the standard errors and the biases the Classical Calibration method outperformed the Inverse Regression method and therefore it is recommended that the Classical Calibration method be used to calibrate the snow gauges.